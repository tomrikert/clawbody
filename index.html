<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ClawBody - Reachy Mini App</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
</head>
<body>

<section class="hero">
    <div class="topline">
        <div class="brand">
            <span class="logo">ğŸ¦</span>
            <span class="brand-name">ClawBody</span>
        </div>
        <div class="pill">Voice conversation Â· OpenClaw AI Â· Expressive motion</div>
    </div>

    <div class="hero-grid">
        <div class="hero-copy">
            <div class="eyebrow">Reachy Mini App</div>
            <h1>Give OpenClaw a physical body.</h1>
            <p class="lede">
                Connect your OpenClaw AI assistant (Clawson) to a Reachy Mini robot. 
                Ultra-responsive voice conversation through OpenAI Realtime API, 
                intelligent responses from OpenClaw, and expressive robot movements.
            </p>
            <div class="hero-actions">
                <a href="#simulator" class="btn primary">ğŸ–¥ï¸ Try with Simulator</a>
                <a href="#features" class="btn ghost">See features</a>
            </div>
            <div class="hero-badges">
                <span>ğŸ™ï¸ OpenAI Realtime</span>
                <span>ğŸ¦ OpenClaw Gateway</span>
                <span>ğŸ’ƒ Expressive movement</span>
                <span>ğŸ–¥ï¸ No robot required!</span>
            </div>
        </div>
        <div class="hero-visual">
            <div class="glass-card">
                <div class="architecture-preview">
<pre>
  You speak â†’ Reachy Mini ğŸ¤
          (or Simulator ğŸ–¥ï¸)
                  â†“
         OpenAI Realtime API
      (speech recognition + TTS)
                  â†“
          OpenClaw Gateway
        (Clawson's brain ğŸ¦)
                  â†“
     Robot speaks & moves ğŸ¤–ğŸ’ƒ
</pre>
                </div>
                <p class="caption">Works with physical robot OR MuJoCo simulator!</p>
            </div>
        </div>
    </div>
</section>

<section class="section simulator-callout" id="simulator">
    <div class="story-card highlight">
        <h2>ğŸ–¥ï¸ No Robot? No Problem!</h2>
        <p class="story-text" style="font-size: 1.1rem;">
            <strong>You don't need a physical Reachy Mini robot to use ClawBody!</strong><br><br>
            ClawBody works with the Reachy Mini Simulator, a MuJoCo-based physics simulation 
            that runs on your computer. Watch Clawson move and express emotions on screen 
            while you talk to your OpenClaw agent.
        </p>
        <div class="architecture-preview" style="margin: 1.5rem 0;">
<pre>
# Install simulator support
pip install "reachy-mini[mujoco]"

# Start the simulator (opens 3D window)
reachy-mini-daemon --sim

# In another terminal, run ClawBody
clawbody --gradio
</pre>
        </div>
        <p class="caption">ğŸ Mac Users: Use <code>mjpython -m reachy_mini.daemon.app.main --sim</code> instead</p>
        <a href="https://huggingface.co/docs/reachy_mini/platforms/simulation/get_started" class="btn primary" style="margin-top: 1rem;" target="_blank">
            ğŸ“š Simulator Setup Guide
        </a>
    </div>
</section>

<section class="section" id="features">
    <div class="section-header">
        <h2>What's inside</h2>
        <p class="intro">
            ClawBody combines real-time voice conversation, OpenClaw intelligence, and expressive robot motion.
        </p>
    </div>
    <div class="feature-grid">
        <div class="feature-card">
            <div class="icon">ğŸ¤</div>
            <h3>Real-time voice</h3>
            <p>Sub-second latency using OpenAI's Realtime API for natural, responsive conversation.</p>
        </div>
        <div class="feature-card">
            <div class="icon">ğŸ¦</div>
            <h3>OpenClaw brain</h3>
            <p>Full Clawson capabilitiesâ€”tools, memory, personalityâ€”through the OpenClaw gateway.</p>
        </div>
        <div class="feature-card">
            <div class="icon">ğŸ‘€</div>
            <h3>Vision</h3>
            <p>See through the robot's camera. Ask Clawson what it sees and get visual descriptions.</p>
        </div>
        <div class="feature-card">
            <div class="icon">ğŸ’ƒ</div>
            <h3>Expressive motion</h3>
            <p>Audio-driven head wobble, emotions, dances, and natural movements while speaking.</p>
        </div>
        <div class="feature-card">
            <div class="icon">ğŸ–¥ï¸</div>
            <h3>Simulator support</h3>
            <p>No robot? Run with MuJoCo simulator and watch Clawson move in a 3D window.</p>
        </div>
        <div class="feature-card">
            <div class="icon">âš¡</div>
            <h3>Hybrid architecture</h3>
            <p>Best of both worlds: OpenAI's voice tech + OpenClaw's full AI capabilities.</p>
        </div>
    </div>
</section>

<section class="section story" id="how-it-works">
    <div class="story-grid">
        <div class="story-card">
            <h3>How it works</h3>
            <p class="story-text">From speech to response in under a second</p>
            <ol class="story-list">
                <li><span>ğŸ¤</span> Robot (or simulator) captures your voice</li>
                <li><span>ğŸ”‡</span> Voice Activity Detection identifies when you stop speaking</li>
                <li><span>ğŸ“</span> OpenAI Realtime transcribes your speech instantly</li>
                <li><span>ğŸ¦</span> OpenClaw processes your message with full AI capabilities</li>
                <li><span>ğŸ”Š</span> OpenAI Realtime speaks the response naturally</li>
                <li><span>ğŸ¤–</span> Robot moves expressively while speaking</li>
            </ol>
        </div>
        <div class="story-card secondary">
            <h3>Prerequisites</h3>
            <p class="story-text">Choose your setup:</p>
            <div class="chips">
                <span class="chip">ğŸ¦ OpenClaw Gateway</span>
                <span class="chip">ğŸ”‘ OpenAI API Key</span>
                <span class="chip">ğŸ Python 3.11+</span>
            </div>
            <p class="story-text" style="margin-top: 1rem;">
                <strong>Option A:</strong> ğŸ¤– Physical Reachy Mini robot<br>
                <strong>Option B:</strong> ğŸ–¥ï¸ MuJoCo Simulator (free, no hardware!)
            </p>
            <a href="https://huggingface.co/spaces/tomrikert/clawbody/blob/main/README.md" class="btn ghost wide" style="margin-top: 1rem;">
                View installation guide
            </a>
        </div>
    </div>
</section>

<section class="section">
    <div class="section-header">
        <h2>Quick start</h2>
        <p class="intro">Get ClawBody running with the simulator</p>
    </div>
    <div class="story-card">
        <div class="architecture-preview">
<pre>
# Clone ClawBody
git clone https://github.com/tomrikert/clawbody
cd clawbody

# Create virtual environment
python -m venv .venv
source .venv/bin/activate

# Install ClawBody + simulator
pip install -e .
pip install "reachy-mini[mujoco]"

# Configure (edit with your OpenClaw URL and OpenAI key)
cp .env.example .env
nano .env

# Terminal 1: Start simulator
reachy-mini-daemon --sim

# Terminal 2: Run ClawBody
clawbody --gradio
</pre>
        </div>
    </div>
</section>

<footer class="footer">
    <p>
        ClawBody â€” giving OpenClaw a physical presence with Reachy Mini.<br>
        <strong>Works with physical robot OR simulator!</strong><br><br>
        Learn more about <a href="https://github.com/openclaw/openclaw">OpenClaw</a>, 
        <a href="https://github.com/pollen-robotics/reachy_mini">Reachy Mini</a>, and
        <a href="https://huggingface.co/docs/reachy_mini/platforms/simulation/get_started">the Simulator</a>.
    </p>
</footer>

</body>
</html>
